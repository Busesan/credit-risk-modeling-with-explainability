{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52eb5d91-97ef-4ce2-a93f-69a7d2c892a9",
   "metadata": {},
   "source": [
    "# 1. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7759e16e-89cb-4c7d-9395-568c27652881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged feature table: (48744, 187)\n",
      "X shape: (48744, 313)\n",
      "NaN left in X: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "\n",
    "DATA_PATH = Path(\"home-credit-default-risk\")\n",
    "\n",
    "# -----------------------\n",
    "# 1) LOAD DATA\n",
    "# -----------------------\n",
    "def load_home_credit_data(data_path: Path):\n",
    "    files = {\n",
    "        \"application_test\": \"application_test.csv\",\n",
    "        \"bureau\": \"bureau.csv\",\n",
    "        \"bureau_balance\": \"bureau_balance.csv\",\n",
    "        \"credit_card_balance\": \"credit_card_balance.csv\",\n",
    "        \"installments_payments\": \"installments_payments.csv\",\n",
    "        \"POS_CASH_balance\": \"POS_CASH_balance.csv\",\n",
    "        \"previous_application\": \"previous_application.csv\",\n",
    "    }\n",
    "    dfs = {k: pd.read_csv(data_path / v) for k, v in files.items()}\n",
    "    return dfs\n",
    "\n",
    "# -----------------------\n",
    "# 2) HELPERS\n",
    "# -----------------------\n",
    "def add_missing_flags(df, cols, suffix=\"_MISSING\"):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c + suffix] = df[c].isna().astype(np.int8)\n",
    "    return df\n",
    "\n",
    "def fix_application_anomalies(df):\n",
    "    \"\"\"\n",
    "    Known Home Credit anomalies:\n",
    "    - DAYS_EMPLOYED == 365243 is a sentinel (unknown). Replace with NaN + flag.\n",
    "    - DAYS_BIRTH is negative days; create AGE_YEARS.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"DAYS_EMPLOYED\" in df.columns:\n",
    "        df[\"DAYS_EMPLOYED_ANOM\"] = (df[\"DAYS_EMPLOYED\"] == 365243).astype(np.int8)\n",
    "        df.loc[df[\"DAYS_EMPLOYED\"] == 365243, \"DAYS_EMPLOYED\"] = np.nan\n",
    "\n",
    "    if \"DAYS_BIRTH\" in df.columns:\n",
    "        df[\"AGE_YEARS\"] = (-df[\"DAYS_BIRTH\"] / 365.25).astype(float)\n",
    "\n",
    "    # Some people also turn DAYS_EMPLOYED into years\n",
    "    if \"DAYS_EMPLOYED\" in df.columns:\n",
    "        df[\"EMPLOYED_YEARS\"] = (-df[\"DAYS_EMPLOYED\"] / 365.25).astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "def safe_ratio(a, b):\n",
    "    \"\"\"Avoid division by zero.\"\"\"\n",
    "    return np.where((b == 0) | pd.isna(b), np.nan, a / b)\n",
    "\n",
    "# -----------------------\n",
    "# 3) AGGREGATIONS (SK_ID_CURR LEVEL)\n",
    "# -----------------------\n",
    "def aggregate_bureau(bureau: pd.DataFrame):\n",
    "    b = bureau.copy()\n",
    "\n",
    "    # simple flags\n",
    "    b[\"CREDIT_ACTIVE_IS_ACTIVE\"] = (b[\"CREDIT_ACTIVE\"] == \"Active\").astype(int)\n",
    "    b[\"CREDIT_ACTIVE_IS_CLOSED\"] = (b[\"CREDIT_ACTIVE\"] == \"Closed\").astype(int)\n",
    "\n",
    "    agg = b.groupby(\"SK_ID_CURR\").agg(\n",
    "        bureau_loan_count=(\"SK_ID_BUREAU\", \"count\"),\n",
    "        bureau_active_loans=(\"CREDIT_ACTIVE_IS_ACTIVE\", \"sum\"),\n",
    "        bureau_closed_loans=(\"CREDIT_ACTIVE_IS_CLOSED\", \"sum\"),\n",
    "        bureau_total_credit_sum=(\"AMT_CREDIT_SUM\", \"sum\"),\n",
    "        bureau_total_credit_mean=(\"AMT_CREDIT_SUM\", \"mean\"),\n",
    "        bureau_debt_sum=(\"AMT_CREDIT_SUM_DEBT\", \"sum\"),\n",
    "        bureau_debt_mean=(\"AMT_CREDIT_SUM_DEBT\", \"mean\"),\n",
    "        bureau_overdue_sum=(\"AMT_CREDIT_SUM_OVERDUE\", \"sum\"),\n",
    "        bureau_overdue_mean=(\"AMT_CREDIT_SUM_OVERDUE\", \"mean\"),\n",
    "        bureau_days_credit_mean=(\"DAYS_CREDIT\", \"mean\"),\n",
    "        bureau_days_enddate_mean=(\"DAYS_CREDIT_ENDDATE\", \"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    return agg\n",
    "\n",
    "def aggregate_bureau_balance(bureau_balance: pd.DataFrame, bureau: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    bureau_balance is keyed by SK_ID_BUREAU, not SK_ID_CURR.\n",
    "    So: aggregate bureau_balance per SK_ID_BUREAU -> merge to bureau -> aggregate to SK_ID_CURR.\n",
    "    \"\"\"\n",
    "    bb = bureau_balance.copy()\n",
    "\n",
    "    # status distributions (0,1,2,3,4,5,C,X)\n",
    "    # We'll compute counts + ratios for \"bad\" statuses\n",
    "    bad_status = {\"1\", \"2\", \"3\", \"4\", \"5\"}\n",
    "    bb[\"BB_IS_BAD\"] = bb[\"STATUS\"].isin(bad_status).astype(int)\n",
    "\n",
    "    bb_agg_bureau = bb.groupby(\"SK_ID_BUREAU\").agg(\n",
    "        bb_months_count=(\"MONTHS_BALANCE\", \"count\"),\n",
    "        bb_bad_months=(\"BB_IS_BAD\", \"sum\"),\n",
    "        bb_latest_month=(\"MONTHS_BALANCE\", \"max\"),\n",
    "        bb_oldest_month=(\"MONTHS_BALANCE\", \"min\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # merge to bureau to get SK_ID_CURR\n",
    "    b = bureau[[\"SK_ID_BUREAU\", \"SK_ID_CURR\"]].merge(bb_agg_bureau, on=\"SK_ID_BUREAU\", how=\"left\")\n",
    "\n",
    "    # aggregate to customer\n",
    "    agg = b.groupby(\"SK_ID_CURR\").agg(\n",
    "        bb_total_months=(\"bb_months_count\", \"sum\"),\n",
    "        bb_total_bad_months=(\"bb_bad_months\", \"sum\"),\n",
    "        bb_avg_latest_month=(\"bb_latest_month\", \"mean\"),\n",
    "        bb_avg_oldest_month=(\"bb_oldest_month\", \"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # add ratio\n",
    "    agg[\"bb_bad_ratio\"] = safe_ratio(agg[\"bb_total_bad_months\"], agg[\"bb_total_months\"])\n",
    "\n",
    "    return agg\n",
    "\n",
    "def aggregate_previous_application(prev: pd.DataFrame):\n",
    "    p = prev.copy()\n",
    "\n",
    "    # contract status flags\n",
    "    p[\"PREV_APPROVED\"] = (p[\"NAME_CONTRACT_STATUS\"] == \"Approved\").astype(int)\n",
    "    p[\"PREV_REFUSED\"] = (p[\"NAME_CONTRACT_STATUS\"] == \"Refused\").astype(int)\n",
    "\n",
    "    # time features: DAYS_DECISION (negative days)\n",
    "    agg = p.groupby(\"SK_ID_CURR\").agg(\n",
    "        prev_app_count=(\"SK_ID_PREV\", \"count\"),\n",
    "        prev_approved=(\"PREV_APPROVED\", \"sum\"),\n",
    "        prev_refused=(\"PREV_REFUSED\", \"sum\"),\n",
    "        prev_credit_mean=(\"AMT_CREDIT\", \"mean\"),\n",
    "        prev_credit_sum=(\"AMT_CREDIT\", \"sum\"),\n",
    "        prev_annuity_mean=(\"AMT_ANNUITY\", \"mean\"),\n",
    "        prev_goods_price_mean=(\"AMT_GOODS_PRICE\", \"mean\"),\n",
    "        prev_days_decision_mean=(\"DAYS_DECISION\", \"mean\"),\n",
    "        prev_days_decision_min=(\"DAYS_DECISION\", \"min\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    agg[\"prev_approval_rate\"] = safe_ratio(agg[\"prev_approved\"], agg[\"prev_app_count\"])\n",
    "    return agg\n",
    "\n",
    "def aggregate_installments(inst: pd.DataFrame):\n",
    "    i = inst.copy()\n",
    "\n",
    "    # Payment behavior\n",
    "    i[\"PAYMENT_DIFF\"] = i[\"AMT_PAYMENT\"] - i[\"AMT_INSTALMENT\"]\n",
    "    i[\"LATE\"] = (i[\"DAYS_ENTRY_PAYMENT\"] > i[\"DAYS_INSTALMENT\"]).astype(int)\n",
    "    i[\"DAYS_LATE\"] = (i[\"DAYS_ENTRY_PAYMENT\"] - i[\"DAYS_INSTALMENT\"]).clip(lower=0)\n",
    "\n",
    "    agg = i.groupby(\"SK_ID_CURR\").agg(\n",
    "        inst_count=(\"SK_ID_PREV\", \"count\"),\n",
    "        inst_late_ratio=(\"LATE\", \"mean\"),\n",
    "        inst_days_late_mean=(\"DAYS_LATE\", \"mean\"),\n",
    "        inst_days_late_max=(\"DAYS_LATE\", \"max\"),\n",
    "        inst_payment_diff_mean=(\"PAYMENT_DIFF\", \"mean\"),\n",
    "        inst_payment_mean=(\"AMT_PAYMENT\", \"mean\"),\n",
    "        inst_instalment_mean=(\"AMT_INSTALMENT\", \"mean\"),\n",
    "        inst_payment_sum=(\"AMT_PAYMENT\", \"sum\"),\n",
    "        inst_instalment_sum=(\"AMT_INSTALMENT\", \"sum\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    agg[\"inst_paid_ratio_sum\"] = safe_ratio(agg[\"inst_payment_sum\"], agg[\"inst_instalment_sum\"])\n",
    "    return agg\n",
    "\n",
    "def aggregate_pos_cash(pos: pd.DataFrame):\n",
    "    p = pos.copy()\n",
    "\n",
    "    p[\"POS_LATE\"] = (p[\"SK_DPD\"] > 0).astype(int)\n",
    "\n",
    "    agg = p.groupby(\"SK_ID_CURR\").agg(\n",
    "        pos_records=(\"SK_ID_PREV\", \"count\"),\n",
    "        pos_unique_prev=(\"SK_ID_PREV\", \"nunique\"),\n",
    "        pos_late_ratio=(\"POS_LATE\", \"mean\"),\n",
    "        pos_skdpd_mean=(\"SK_DPD\", \"mean\"),\n",
    "        pos_skdpd_max=(\"SK_DPD\", \"max\"),\n",
    "        pos_months_balance_min=(\"MONTHS_BALANCE\", \"min\"),\n",
    "        pos_months_balance_max=(\"MONTHS_BALANCE\", \"max\"),\n",
    "    ).reset_index()\n",
    "    return agg\n",
    "\n",
    "def aggregate_credit_card(cc: pd.DataFrame):\n",
    "    c = cc.copy()\n",
    "\n",
    "    # utilization proxy: balance / limit (limit can be 0 or missing)\n",
    "    if \"AMT_CREDIT_LIMIT_ACTUAL\" in c.columns and \"AMT_BALANCE\" in c.columns:\n",
    "        c[\"CC_UTIL\"] = safe_ratio(c[\"AMT_BALANCE\"], c[\"AMT_CREDIT_LIMIT_ACTUAL\"])\n",
    "    else:\n",
    "        c[\"CC_UTIL\"] = np.nan\n",
    "\n",
    "    agg = c.groupby(\"SK_ID_CURR\").agg(\n",
    "        cc_records=(\"SK_ID_PREV\", \"count\"),\n",
    "        cc_unique_prev=(\"SK_ID_PREV\", \"nunique\"),\n",
    "        cc_balance_mean=(\"AMT_BALANCE\", \"mean\"),\n",
    "        cc_balance_max=(\"AMT_BALANCE\", \"max\"),\n",
    "        cc_limit_mean=(\"AMT_CREDIT_LIMIT_ACTUAL\", \"mean\"),\n",
    "        cc_util_mean=(\"CC_UTIL\", \"mean\"),\n",
    "        cc_skdpd_mean=(\"SK_DPD\", \"mean\") if \"SK_DPD\" in c.columns else (\"CC_UTIL\", \"mean\"),\n",
    "        cc_skdpd_max=(\"SK_DPD\", \"max\") if \"SK_DPD\" in c.columns else (\"CC_UTIL\", \"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    return agg\n",
    "\n",
    "# -----------------------\n",
    "# 4) MERGE ALL FEATURES\n",
    "# -----------------------\n",
    "def build_feature_table(dfs):\n",
    "    app = dfs[\"application_test\"].copy()\n",
    "    app = fix_application_anomalies(app)\n",
    "\n",
    "    # simple ratios in app\n",
    "    for col in [\"AMT_CREDIT\", \"AMT_ANNUITY\", \"AMT_INCOME_TOTAL\"]:\n",
    "        if col not in app.columns:\n",
    "            raise ValueError(f\"Missing expected column in application_test: {col}\")\n",
    "\n",
    "    app[\"CREDIT_INCOME_RATIO\"] = safe_ratio(app[\"AMT_CREDIT\"], app[\"AMT_INCOME_TOTAL\"])\n",
    "    app[\"ANNUITY_INCOME_RATIO\"] = safe_ratio(app[\"AMT_ANNUITY\"], app[\"AMT_INCOME_TOTAL\"])\n",
    "    app[\"CREDIT_TERM\"] = safe_ratio(app[\"AMT_CREDIT\"], app[\"AMT_ANNUITY\"])\n",
    "\n",
    "    # Aggregations\n",
    "    bureau_agg = aggregate_bureau(dfs[\"bureau\"])\n",
    "    bb_agg = aggregate_bureau_balance(dfs[\"bureau_balance\"], dfs[\"bureau\"])\n",
    "    prev_agg = aggregate_previous_application(dfs[\"previous_application\"])\n",
    "    inst_agg = aggregate_installments(dfs[\"installments_payments\"])\n",
    "    pos_agg = aggregate_pos_cash(dfs[\"POS_CASH_balance\"])\n",
    "    cc_agg = aggregate_credit_card(dfs[\"credit_card_balance\"])\n",
    "\n",
    "    # Merge into app\n",
    "    out = app.merge(bureau_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    out = out.merge(bb_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    out = out.merge(prev_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    out = out.merge(inst_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    out = out.merge(pos_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    out = out.merge(cc_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "    # Missing flags for strategic columns (value + missingness both can be predictive)\n",
    "    strategic = [c for c in [\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\",\n",
    "                            \"bureau_debt_sum\", \"bb_bad_ratio\",\n",
    "                            \"prev_approval_rate\", \"inst_late_ratio\",\n",
    "                            \"cc_util_mean\", \"pos_late_ratio\"] if c in out.columns]\n",
    "    out = add_missing_flags(out, strategic)\n",
    "\n",
    "    return out\n",
    "\n",
    "# -----------------------\n",
    "# 5) CLEANING + ENCODING\n",
    "# -----------------------\n",
    "def clean_and_encode(full_df, target_col=\"TARGET\", drop_cols=(\"SK_ID_CURR\",), fill_cat=\"Unknown\"):\n",
    "    df = full_df.copy()\n",
    "\n",
    "    # Identify columns\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "    num_cols = df.select_dtypes(exclude=\"object\").columns.tolist()\n",
    "\n",
    "    # Fill categorical\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].fillna(fill_cat)\n",
    "\n",
    "    # Fill numeric (median), excluding target\n",
    "    if target_col in df.columns:\n",
    "        num_cols_wo_target = [c for c in num_cols if c != target_col]\n",
    "    else:\n",
    "        num_cols_wo_target = num_cols\n",
    "\n",
    "    medians = {}\n",
    "    for c in num_cols_wo_target:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            med = df[c].median()\n",
    "            medians[c] = med\n",
    "            df[c] = df[c].fillna(med)\n",
    "\n",
    "    # Build X\n",
    " \n",
    "    X = df.drop(columns=[target_col], errors=\"ignore\")\n",
    "\n",
    "    # drop IDs\n",
    "    for c in drop_cols:\n",
    "        if c in X.columns:\n",
    "            X = X.drop(columns=[c])\n",
    "\n",
    "    # One-hot encode\n",
    "    X = pd.get_dummies(X, dummy_na=False)\n",
    "\n",
    "    return X, df, medians\n",
    "\n",
    "# -----------------------\n",
    "# 6) RUN PIPELINE\n",
    "# -----------------------\n",
    "dfs = load_home_credit_data(DATA_PATH)\n",
    "\n",
    "full_features = build_feature_table(dfs)\n",
    "print(\"Merged feature table:\", full_features.shape)\n",
    "\n",
    "X, cleaned_df, medians = clean_and_encode(full_features)\n",
    "print(\"X shape:\", X.shape)\n",
    "\n",
    "# Sanity checks\n",
    "print(\"NaN left in X:\", int(X.isna().any().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107119be-f800-47ce-b9e7-6cb00a568221",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa3002-0155-4add-8427-4b5b649fca27",
   "metadata": {},
   "source": [
    "# 2.a. Application Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4cbf5a-ba4d-47e2-9f6a-2383d9343986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def add_app_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Basic ratios (some already in your pipeline, keep safe)\n",
    "    if {\"AMT_CREDIT\",\"AMT_INCOME_TOTAL\"}.issubset(df.columns):\n",
    "        df[\"FE_CREDIT_INCOME_RATIO\"] = df[\"AMT_CREDIT\"] / df[\"AMT_INCOME_TOTAL\"].replace(0, np.nan)\n",
    "\n",
    "    if {\"AMT_ANNUITY\",\"AMT_INCOME_TOTAL\"}.issubset(df.columns):\n",
    "        df[\"FE_ANNUITY_INCOME_RATIO\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_INCOME_TOTAL\"].replace(0, np.nan)\n",
    "\n",
    "    if {\"AMT_CREDIT\",\"AMT_ANNUITY\"}.issubset(df.columns):\n",
    "        df[\"FE_CREDIT_TERM\"] = df[\"AMT_CREDIT\"] / df[\"AMT_ANNUITY\"].replace(0, np.nan)\n",
    "\n",
    "    if {\"AMT_GOODS_PRICE\",\"AMT_CREDIT\"}.issubset(df.columns):\n",
    "        df[\"FE_GOODS_CREDIT_RATIO\"] = df[\"AMT_GOODS_PRICE\"] / df[\"AMT_CREDIT\"].replace(0, np.nan)\n",
    "\n",
    "    # --- Family / children normalization\n",
    "    if {\"CNT_FAM_MEMBERS\",\"AMT_INCOME_TOTAL\"}.issubset(df.columns):\n",
    "        df[\"FE_INCOME_PER_FAMILY\"] = df[\"AMT_INCOME_TOTAL\"] / df[\"CNT_FAM_MEMBERS\"].replace(0, np.nan)\n",
    "\n",
    "    if {\"CNT_CHILDREN\",\"CNT_FAM_MEMBERS\"}.issubset(df.columns):\n",
    "        df[\"FE_CHILDREN_RATIO\"] = df[\"CNT_CHILDREN\"] / df[\"CNT_FAM_MEMBERS\"].replace(0, np.nan)\n",
    "\n",
    "    # --- Document / flag counts (these are weak individually, stronger as totals)\n",
    "    doc_cols = [c for c in df.columns if c.startswith(\"FLAG_DOC\")]\n",
    "    if doc_cols:\n",
    "        df[\"FE_FLAG_DOC_SUM\"] = df[doc_cols].sum(axis=1)\n",
    "\n",
    "    flag_cols = [c for c in df.columns if c.startswith(\"FLAG_\") and c not in doc_cols]\n",
    "    # Some FLAG_* are binary; sum can act as \"how many flags\"\n",
    "    if flag_cols:\n",
    "        # keep it bounded: ensure numeric\n",
    "        df[\"FE_FLAG_SUM\"] = df[flag_cols].select_dtypes(exclude=\"object\").sum(axis=1)\n",
    "\n",
    "    # --- External sources: mean / min / max / std + missing count\n",
    "    ext = [c for c in [\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"] if c in df.columns]\n",
    "    if ext:\n",
    "        df[\"FE_EXT_MEAN\"] = df[ext].mean(axis=1)\n",
    "        df[\"FE_EXT_MIN\"] = df[ext].min(axis=1)\n",
    "        df[\"FE_EXT_MAX\"] = df[ext].max(axis=1)\n",
    "        df[\"FE_EXT_STD\"] = df[ext].std(axis=1)\n",
    "        df[\"FE_EXT_MISSING_COUNT\"] = df[ext].isna().sum(axis=1)\n",
    "\n",
    "    # --- Age / employment interactions (if you created AGE_YEARS / EMPLOYED_YEARS)\n",
    "    if {\"AGE_YEARS\",\"EMPLOYED_YEARS\"}.issubset(df.columns):\n",
    "        df[\"FE_EMPLOYED_AGE_RATIO\"] = df[\"EMPLOYED_YEARS\"] / df[\"AGE_YEARS\"].replace(0, np.nan)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575aa254-674f-4071-95d9-5cd51f03580e",
   "metadata": {},
   "source": [
    "# 2.b. Recent Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50b647c-1c79-400e-a6a4-a8ce5cae13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_recent_installment_features(inst: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    installments_payments: DAYS_INSTALMENT negative (past).\n",
    "    We'll define \"recent window\" by DAYS_INSTALMENT >= -365 (last 12 months), >= -180 (last 6 months).\n",
    "    Returns SK_ID_CURR-level features.\n",
    "    \"\"\"\n",
    "    i = inst.copy()\n",
    "\n",
    "    i[\"LATE\"] = (i[\"DAYS_ENTRY_PAYMENT\"] > i[\"DAYS_INSTALMENT\"]).astype(int)\n",
    "    i[\"DAYS_LATE\"] = (i[\"DAYS_ENTRY_PAYMENT\"] - i[\"DAYS_INSTALMENT\"]).clip(lower=0)\n",
    "\n",
    "    feats = []\n",
    "    for window, name in [(365, \"12M\"), (180, \"6M\")]:\n",
    "        recent = i[i[\"DAYS_INSTALMENT\"] >= -window].copy()\n",
    "        agg = recent.groupby(\"SK_ID_CURR\").agg(\n",
    "            **{\n",
    "                f\"FE_INST_LATE_RATIO_{name}\": (\"LATE\", \"mean\"),\n",
    "                f\"FE_INST_DAYS_LATE_MEAN_{name}\": (\"DAYS_LATE\", \"mean\"),\n",
    "                f\"FE_INST_COUNT_{name}\": (\"SK_ID_PREV\", \"count\"),\n",
    "            }\n",
    "        ).reset_index()\n",
    "        feats.append(agg)\n",
    "\n",
    "    # merge the two windows together\n",
    "    out = feats[0]\n",
    "    out = out.merge(feats[1], on=\"SK_ID_CURR\", how=\"outer\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac5294-2cda-4006-95a0-3e2ece8c014f",
   "metadata": {},
   "source": [
    "# POS: SK-DPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3f9bfe8-4955-4212-bc83-4d36ec198045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_recent_pos_features(pos: pd.DataFrame) -> pd.DataFrame:\n",
    "    p = pos.copy()\n",
    "    p[\"POS_LATE\"] = (p[\"SK_DPD\"] > 0).astype(int)\n",
    "\n",
    "    feats = []\n",
    "    for window, name in [(12, \"12M\"), (6, \"6M\")]:\n",
    "        # MONTHS_BALANCE: 0 is current, -1 previous month, etc.\n",
    "        recent = p[p[\"MONTHS_BALANCE\"] >= -window].copy()\n",
    "        agg = recent.groupby(\"SK_ID_CURR\").agg(\n",
    "            **{\n",
    "                f\"FE_POS_LATE_RATIO_{name}\": (\"POS_LATE\", \"mean\"),\n",
    "                f\"FE_POS_SKDPD_MEAN_{name}\": (\"SK_DPD\", \"mean\"),\n",
    "                f\"FE_POS_COUNT_{name}\": (\"SK_ID_PREV\", \"count\"),\n",
    "            }\n",
    "        ).reset_index()\n",
    "        feats.append(agg)\n",
    "\n",
    "    out = feats[0].merge(feats[1], on=\"SK_ID_CURR\", how=\"outer\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ba61c-daa5-4401-bda7-2fee92296b7a",
   "metadata": {},
   "source": [
    "# Credit Card: utilization / balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94953726-2723-40da-ada0-0cda3e9513cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_recent_cc_features(cc: pd.DataFrame) -> pd.DataFrame:\n",
    "    c = cc.copy()\n",
    "\n",
    "    if {\"AMT_BALANCE\",\"AMT_CREDIT_LIMIT_ACTUAL\"}.issubset(c.columns):\n",
    "        c[\"CC_UTIL\"] = c[\"AMT_BALANCE\"] / c[\"AMT_CREDIT_LIMIT_ACTUAL\"].replace(0, np.nan)\n",
    "    else:\n",
    "        c[\"CC_UTIL\"] = np.nan\n",
    "\n",
    "    feats = []\n",
    "    for window, name in [(12, \"12M\"), (6, \"6M\")]:\n",
    "        recent = c[c[\"MONTHS_BALANCE\"] >= -window].copy()\n",
    "        agg = recent.groupby(\"SK_ID_CURR\").agg(\n",
    "            **{\n",
    "                f\"FE_CC_UTIL_MEAN_{name}\": (\"CC_UTIL\", \"mean\"),\n",
    "                f\"FE_CC_BAL_MEAN_{name}\": (\"AMT_BALANCE\", \"mean\"),\n",
    "                f\"FE_CC_COUNT_{name}\": (\"SK_ID_PREV\", \"count\"),\n",
    "            }\n",
    "        ).reset_index()\n",
    "        feats.append(agg)\n",
    "\n",
    "    out = feats[0].merge(feats[1], on=\"SK_ID_CURR\", how=\"outer\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf36e9-a50e-426b-b804-4f4fd9f003f0",
   "metadata": {},
   "source": [
    "# 2.c. Group-based normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51113426-7b7e-4af9-985c-c26bcbc48216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group_zscores(df: pd.DataFrame, group_col: str, value_cols: list[str]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if group_col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    for v in value_cols:\n",
    "        if v not in df.columns:\n",
    "            continue\n",
    "        grp_mean = df.groupby(group_col)[v].transform(\"mean\")\n",
    "        grp_std = df.groupby(group_col)[v].transform(\"std\")\n",
    "        df[f\"FE_{v}_Z_IN_{group_col}\"] = (df[v] - grp_mean) / grp_std.replace(0, np.nan)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8d4a92-c999-4d43-9c14-9a1b6ae7e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shapes: (48744, 383)\n",
      "NaN left in X: 0\n"
     ]
    }
   ],
   "source": [
    "# --- 1) full_features \n",
    "full_features = build_feature_table(dfs)\n",
    "\n",
    "# --- 2) app-level FE ---\n",
    "full_features = add_app_features(full_features)\n",
    "\n",
    "# --- 3) recent behavior FE from raw tables ---\n",
    "inst_recent = add_recent_installment_features(dfs[\"installments_payments\"])\n",
    "pos_recent  = add_recent_pos_features(dfs[\"POS_CASH_balance\"])\n",
    "cc_recent   = add_recent_cc_features(dfs[\"credit_card_balance\"])\n",
    "\n",
    "full_features = full_features.merge(inst_recent, on=\"SK_ID_CURR\", how=\"left\")\n",
    "full_features = full_features.merge(pos_recent,  on=\"SK_ID_CURR\", how=\"left\")\n",
    "full_features = full_features.merge(cc_recent,   on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# --- 4) group-based z-scores  ---\n",
    "full_features = add_group_zscores(\n",
    "    full_features,\n",
    "    group_col=\"ORGANIZATION_TYPE\",\n",
    "    value_cols=[c for c in [\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\"] if c in full_features.columns]\n",
    ")\n",
    "\n",
    "# --- 5) Add missing flags for the new engineered features too (keep signal)\n",
    "engineered_cols = [c for c in full_features.columns if c.startswith(\"FE_\")]\n",
    "full_features = add_missing_flags(full_features, engineered_cols[:60])  # limit: too many flags can explode\n",
    "\n",
    "# --- 6) Clean + encode into X ---\n",
    "X, cleaned_df, medians = clean_and_encode(full_features)\n",
    "\n",
    "print(\"Final shapes:\", X.shape)\n",
    "print(\"NaN left in X:\", int(X.isna().any().sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321c2e23-ff9c-4613-a9dc-85433712676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df_train = pd.read_csv(\"fs_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f31b365-8cd4-42eb-ad16-b1138d168466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = list(set(fs_df_train.columns) - set(['TARGET']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d003afb4-cb77-4ed6-be21-bfa0891e590f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inst_days_late_max',\n",
       " 'FLOORSMIN_AVG',\n",
       " 'EXT_SOURCE_3_MISSING',\n",
       " 'FE_FLAG_SUM',\n",
       " 'FE_GOODS_CREDIT_RATIO',\n",
       " 'FE_EXT_STD_MISSING',\n",
       " 'LIVE_CITY_NOT_WORK_CITY',\n",
       " 'bureau_days_enddate_mean',\n",
       " 'YEARS_BEGINEXPLUATATION_AVG',\n",
       " 'bureau_overdue_mean',\n",
       " 'FE_POS_COUNT_12M',\n",
       " 'FE_POS_LATE_RATIO_12M',\n",
       " 'bureau_debt_mean',\n",
       " 'inst_late_ratio',\n",
       " 'FE_POS_LATE_RATIO_6M',\n",
       " 'FE_CC_BAL_MEAN_12M',\n",
       " 'bureau_overdue_sum',\n",
       " 'FLAG_PHONE',\n",
       " 'BASEMENTAREA_AVG',\n",
       " 'bureau_days_credit_mean',\n",
       " 'REG_CITY_NOT_LIVE_CITY',\n",
       " 'EXT_SOURCE_3',\n",
       " 'AMT_CREDIT',\n",
       " 'DAYS_EMPLOYED',\n",
       " 'inst_count',\n",
       " 'ORGANIZATION_TYPE',\n",
       " 'bb_bad_ratio',\n",
       " 'APARTMENTS_AVG',\n",
       " 'OCCUPATION_TYPE',\n",
       " 'FE_POS_SKDPD_MEAN_12M',\n",
       " 'CNT_CHILDREN',\n",
       " 'ELEVATORS_AVG',\n",
       " 'AMT_INCOME_TOTAL',\n",
       " 'prev_annuity_mean',\n",
       " 'FE_INST_LATE_RATIO_6M',\n",
       " 'inst_payment_mean',\n",
       " 'prev_refused',\n",
       " 'inst_days_late_mean',\n",
       " 'pos_skdpd_mean',\n",
       " 'pos_months_balance_min',\n",
       " 'FE_INST_DAYS_LATE_MEAN_6M',\n",
       " 'COMMONAREA_AVG',\n",
       " 'NAME_HOUSING_TYPE',\n",
       " 'EMERGENCYSTATE_MODE',\n",
       " 'FE_CC_COUNT_12M',\n",
       " 'LIVINGAREA_AVG',\n",
       " 'FE_EXT_MIN',\n",
       " 'EXT_SOURCE_1',\n",
       " 'NAME_EDUCATION_TYPE',\n",
       " 'LIVINGAPARTMENTS_AVG',\n",
       " 'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
       " 'FLAG_EMP_PHONE',\n",
       " 'prev_credit_mean',\n",
       " 'FE_FLAG_DOC_SUM',\n",
       " 'EXT_SOURCE_2',\n",
       " 'NAME_FAMILY_STATUS',\n",
       " 'WALLSMATERIAL_MODE',\n",
       " 'FE_CC_UTIL_MEAN_12M',\n",
       " 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
       " 'prev_days_decision_min',\n",
       " 'pos_skdpd_max',\n",
       " 'ANNUITY_INCOME_RATIO',\n",
       " 'REGION_POPULATION_RELATIVE',\n",
       " 'cc_balance_max',\n",
       " 'DAYS_ID_PUBLISH',\n",
       " 'inst_late_ratio_MISSING',\n",
       " 'DAYS_LAST_PHONE_CHANGE',\n",
       " 'pos_months_balance_max',\n",
       " 'FE_INCOME_PER_FAMILY',\n",
       " 'FONDKAPREMONT_MODE',\n",
       " 'YEARS_BUILD_AVG',\n",
       " 'FE_EXT_MAX',\n",
       " 'bureau_debt_sum',\n",
       " 'pos_unique_prev',\n",
       " 'bureau_active_loans',\n",
       " 'FLAG_OWN_CAR',\n",
       " 'cc_records',\n",
       " 'EXT_SOURCE_1_MISSING',\n",
       " 'CREDIT_TERM',\n",
       " 'cc_util_mean_MISSING',\n",
       " 'prev_approval_rate',\n",
       " 'FE_CC_UTIL_MEAN_12M_MISSING',\n",
       " 'LANDAREA_AVG',\n",
       " 'NAME_CONTRACT_TYPE',\n",
       " 'cc_balance_mean',\n",
       " 'TOTALAREA_MODE',\n",
       " 'FE_AMT_INCOME_TOTAL_Z_IN_ORGANIZATION_TYPE',\n",
       " 'bureau_debt_sum_MISSING',\n",
       " 'NAME_TYPE_SUITE',\n",
       " 'FE_INST_DAYS_LATE_MEAN_12M',\n",
       " 'REG_CITY_NOT_WORK_CITY',\n",
       " 'inst_payment_sum',\n",
       " 'FE_INST_COUNT_12M',\n",
       " 'FE_POS_LATE_RATIO_6M_MISSING',\n",
       " 'DAYS_REGISTRATION',\n",
       " 'bb_total_bad_months',\n",
       " 'prev_app_count',\n",
       " 'prev_approved',\n",
       " 'FE_EXT_MISSING_COUNT',\n",
       " 'cc_util_mean',\n",
       " 'FLAG_WORK_PHONE',\n",
       " 'FE_POS_COUNT_6M',\n",
       " 'bb_avg_latest_month',\n",
       " 'inst_paid_ratio_sum',\n",
       " 'FE_EXT_STD',\n",
       " 'FE_CC_COUNT_6M',\n",
       " 'pos_records',\n",
       " 'NAME_INCOME_TYPE',\n",
       " 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
       " 'prev_days_decision_mean',\n",
       " 'bureau_closed_loans',\n",
       " 'prev_goods_price_mean',\n",
       " 'OWN_CAR_AGE',\n",
       " 'REGION_RATING_CLIENT',\n",
       " 'inst_payment_diff_mean',\n",
       " 'FE_INST_LATE_RATIO_12M',\n",
       " 'pos_late_ratio',\n",
       " 'HOUSETYPE_MODE',\n",
       " 'bureau_total_credit_sum',\n",
       " 'DAYS_BIRTH',\n",
       " 'bureau_total_credit_mean',\n",
       " 'prev_approval_rate_MISSING',\n",
       " 'FE_INST_COUNT_6M',\n",
       " 'ENTRANCES_AVG',\n",
       " 'FE_EXT_MEAN',\n",
       " 'HOUR_APPR_PROCESS_START',\n",
       " 'CODE_GENDER',\n",
       " 'FLOORSMAX_AVG',\n",
       " 'pos_late_ratio_MISSING',\n",
       " 'NONLIVINGAREA_AVG']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "384bd3c9-afb5-4316-93cb-524ef921b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df_test = cleaned_df[train_cols + ['SK_ID_CURR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "651f4849-7918-4ef3-8d37-3c23ba96425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features: (48744, 131)\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining features:\", fs_df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00d4ab95-46bd-455b-8352-2408523d48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df_test.to_csv(\"fs_df_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
